{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4396,
     "status": "ok",
     "timestamp": 1658293844350,
     "user": {
      "displayName": "문지현",
      "userId": "07420081825015725286"
     },
     "user_tz": -540
    },
    "id": "OZPaFt-bJ9Xx",
    "outputId": "281b3bc4-51e7-4c33-a890-d85f7bafbf1e"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53393,
     "status": "ok",
     "timestamp": 1658293897729,
     "user": {
      "displayName": "문지현",
      "userId": "07420081825015725286"
     },
     "user_tz": -540
    },
    "id": "xuAWFBQlvu7w",
    "outputId": "ecbb66b6-caf5-4b82-93da-5d7a25d7a351"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mxnet\n",
      "  Using cached mxnet-1.7.0.post2-py2.py3-none-win_amd64.whl (33.1 MB)\n",
      "Collecting requests<2.19.0,>=2.18.4\n",
      "  Using cached requests-2.18.4-py2.py3-none-any.whl (88 kB)\n",
      "Collecting numpy<1.17.0,>=1.8.2\n",
      "  Using cached numpy-1.16.6-cp36-cp36m-win_amd64.whl (11.9 MB)\n",
      "Collecting graphviz<0.9.0,>=0.8.1\n",
      "  Using cached graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from requests<2.19.0,>=2.18.4->mxnet) (2021.5.30)\n",
      "Collecting idna<2.7,>=2.5\n",
      "  Using cached idna-2.6-py2.py3-none-any.whl (56 kB)\n",
      "Collecting urllib3<1.23,>=1.21.1\n",
      "  Using cached urllib3-1.22-py2.py3-none-any.whl (132 kB)\n",
      "Collecting chardet<3.1.0,>=3.0.2\n",
      "  Using cached chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "Installing collected packages: urllib3, idna, chardet, requests, numpy, graphviz, mxnet\n",
      "Successfully installed chardet-3.0.4 graphviz-0.8.4 idna-2.6 mxnet-1.7.0.post2 numpy-1.16.6 requests-2.18.4 urllib3-1.22\n"
     ]
    }
   ],
   "source": [
    "## 불러오기 방법 1\n",
    "#모델을 저장한 이후 학습한 모델을 불러와 사용해야할 코드는 다음과 같다.\n",
    "!pip install mxnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53393,
     "status": "ok",
     "timestamp": 1658293897729,
     "user": {
      "displayName": "문지현",
      "userId": "07420081825015725286"
     },
     "user_tz": -540
    },
    "id": "xuAWFBQlvu7w",
    "outputId": "ecbb66b6-caf5-4b82-93da-5d7a25d7a351"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wheel in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (0.37.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53393,
     "status": "ok",
     "timestamp": 1658293897729,
     "user": {
      "displayName": "문지현",
      "userId": "07420081825015725286"
     },
     "user_tz": -540
    },
    "id": "xuAWFBQlvu7w",
    "outputId": "ecbb66b6-caf5-4b82-93da-5d7a25d7a351"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gluonnlp\n",
      "  Using cached gluonnlp-0.10.0.tar.gz (344 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (1.0.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (4.64.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from gluonnlp) (1.16.6)\n",
      "Requirement already satisfied: cython in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from gluonnlp) (0.29.30)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from gluonnlp) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from tqdm) (5.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from tqdm) (0.4.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from python-dateutil>=2.6.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from importlib-resources->tqdm) (3.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from packaging->gluonnlp) (3.0.9)\n",
      "Building wheels for collected packages: gluonnlp\n",
      "  Building wheel for gluonnlp (setup.py): started\n",
      "  Building wheel for gluonnlp (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for gluonnlp\n",
      "Failed to build gluonnlp\n",
      "Installing collected packages: gluonnlp\n",
      "    Running setup.py install for gluonnlp: started\n",
      "    Running setup.py install for gluonnlp: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\Users\\User\\na\\envs\\kobert\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\User\\\\AppData\\\\Local\\\\Temp\\\\pip-install-1o02l1hm\\\\gluonnlp_1661501b992548a39b10db7fae2c0755\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\User\\\\AppData\\\\Local\\\\Temp\\\\pip-install-1o02l1hm\\\\gluonnlp_1661501b992548a39b10db7fae2c0755\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\User\\AppData\\Local\\Temp\\pip-wheel-6uaydtve'\n",
      "       cwd: C:\\Users\\User\\AppData\\Local\\Temp\\pip-install-1o02l1hm\\gluonnlp_1661501b992548a39b10db7fae2c0755\\\n",
      "  Complete output (124 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-3.6\n",
      "  creating build\\lib.win-amd64-3.6\\gluonnlp\n",
      "  copying src\\gluonnlp\\base.py -> build\\lib.win-amd64-3.6\\gluonnlp\n",
      "  copying src\\gluonnlp\\_constants.py -> build\\lib.win-amd64-3.6\\gluonnlp\n",
      "  copying src\\gluonnlp\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\n",
      "  creating build\\lib.win-amd64-3.6\\gluonnlp\\calibration\n",
      "  copying src\\gluonnlp\\calibration\\collector.py -> build\\lib.win-amd64-3.6\\gluonnlp\\calibration\n",
      "  copying src\\gluonnlp\\calibration\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\calibration\n",
      "  creating build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\baidu_ernie_data.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\candidate_sampler.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\classification.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\conll.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\dataloader.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\dataset.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\datasetloader.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\glue.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\intent_slot.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\question_answering.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\registry.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\sampler.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\sentiment.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\stream.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\super_glue.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\transforms.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\translation.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\utils.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\word_embedding_evaluation.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  creating build\\lib.win-amd64-3.6\\gluonnlp\\embedding\n",
      "  copying src\\gluonnlp\\embedding\\evaluation.py -> build\\lib.win-amd64-3.6\\gluonnlp\\embedding\n",
      "  copying src\\gluonnlp\\embedding\\token_embedding.py -> build\\lib.win-amd64-3.6\\gluonnlp\\embedding\n",
      "  copying src\\gluonnlp\\embedding\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\embedding\n",
      "  creating build\\lib.win-amd64-3.6\\gluonnlp\\initializer\n",
      "  copying src\\gluonnlp\\initializer\\initializer.py -> build\\lib.win-amd64-3.6\\gluonnlp\\initializer\n",
      "  copying src\\gluonnlp\\initializer\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\initializer\n",
      "  creating build\\lib.win-amd64-3.6\\gluonnlp\\loss\n",
      "  copying src\\gluonnlp\\loss\\activation_regularizer.py -> build\\lib.win-amd64-3.6\\gluonnlp\\loss\n",
      "  copying src\\gluonnlp\\loss\\label_smoothing.py -> build\\lib.win-amd64-3.6\\gluonnlp\\loss\n",
      "  copying src\\gluonnlp\\loss\\loss.py -> build\\lib.win-amd64-3.6\\gluonnlp\\loss\n",
      "  copying src\\gluonnlp\\loss\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\loss\n",
      "  creating build\\lib.win-amd64-3.6\\gluonnlp\\metric\n",
      "  copying src\\gluonnlp\\metric\\length_normalized_loss.py -> build\\lib.win-amd64-3.6\\gluonnlp\\metric\n",
      "  copying src\\gluonnlp\\metric\\masked_accuracy.py -> build\\lib.win-amd64-3.6\\gluonnlp\\metric\n",
      "  copying src\\gluonnlp\\metric\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\metric\n",
      "  creating build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\attention_cell.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\bert.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\bilm_encoder.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\block.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\convolutional_encoder.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\elmo.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\highway.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\info.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\language_model.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\lstmpcellwithclip.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\parameter.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\sampled_block.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\seq2seq_encoder_decoder.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\sequence_sampler.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\transformer.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\translation.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\utils.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "  creating build\\lib.win-amd64-3.6\\gluonnlp\\optimizer\n",
      "  copying src\\gluonnlp\\optimizer\\bert_adam.py -> build\\lib.win-amd64-3.6\\gluonnlp\\optimizer\n",
      "  copying src\\gluonnlp\\optimizer\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\optimizer\n",
      "  creating build\\lib.win-amd64-3.6\\gluonnlp\\utils\n",
      "  copying src\\gluonnlp\\utils\\files.py -> build\\lib.win-amd64-3.6\\gluonnlp\\utils\n",
      "  copying src\\gluonnlp\\utils\\parallel.py -> build\\lib.win-amd64-3.6\\gluonnlp\\utils\n",
      "  copying src\\gluonnlp\\utils\\parameter.py -> build\\lib.win-amd64-3.6\\gluonnlp\\utils\n",
      "  copying src\\gluonnlp\\utils\\seed.py -> build\\lib.win-amd64-3.6\\gluonnlp\\utils\n",
      "  copying src\\gluonnlp\\utils\\version.py -> build\\lib.win-amd64-3.6\\gluonnlp\\utils\n",
      "  copying src\\gluonnlp\\utils\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\utils\n",
      "  creating build\\lib.win-amd64-3.6\\gluonnlp\\vocab\n",
      "  copying src\\gluonnlp\\vocab\\bert.py -> build\\lib.win-amd64-3.6\\gluonnlp\\vocab\n",
      "  copying src\\gluonnlp\\vocab\\elmo.py -> build\\lib.win-amd64-3.6\\gluonnlp\\vocab\n",
      "  copying src\\gluonnlp\\vocab\\subwords.py -> build\\lib.win-amd64-3.6\\gluonnlp\\vocab\n",
      "  copying src\\gluonnlp\\vocab\\vocab.py -> build\\lib.win-amd64-3.6\\gluonnlp\\vocab\n",
      "  copying src\\gluonnlp\\vocab\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\vocab\n",
      "  creating build\\lib.win-amd64-3.6\\gluonnlp\\data\\batchify\n",
      "  copying src\\gluonnlp\\data\\batchify\\batchify.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\batchify\n",
      "  copying src\\gluonnlp\\data\\batchify\\embedding.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\batchify\n",
      "  copying src\\gluonnlp\\data\\batchify\\language_model.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\batchify\n",
      "  copying src\\gluonnlp\\data\\batchify\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\batchify\n",
      "  creating build\\lib.win-amd64-3.6\\gluonnlp\\data\\bert\n",
      "  copying src\\gluonnlp\\data\\bert\\glue.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\bert\n",
      "  copying src\\gluonnlp\\data\\bert\\squad.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\bert\n",
      "  copying src\\gluonnlp\\data\\bert\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\bert\n",
      "  creating build\\lib.win-amd64-3.6\\gluonnlp\\data\\corpora\n",
      "  copying src\\gluonnlp\\data\\corpora\\google_billion_word.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\corpora\n",
      "  copying src\\gluonnlp\\data\\corpora\\large_text_compression_benchmark.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\corpora\n",
      "  copying src\\gluonnlp\\data\\corpora\\wikitext.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\corpora\n",
      "  copying src\\gluonnlp\\data\\corpora\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\corpora\n",
      "  creating build\\lib.win-amd64-3.6\\gluonnlp\\data\\xlnet\n",
      "  copying src\\gluonnlp\\data\\xlnet\\squad.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\xlnet\n",
      "  copying src\\gluonnlp\\data\\xlnet\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\xlnet\n",
      "  creating build\\lib.win-amd64-3.6\\gluonnlp\\model\\train\n",
      "  copying src\\gluonnlp\\model\\train\\cache.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\\train\n",
      "  copying src\\gluonnlp\\model\\train\\embedding.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\\train\n",
      "  copying src\\gluonnlp\\model\\train\\language_model.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\\train\n",
      "  copying src\\gluonnlp\\model\\train\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\\train\n",
      "  running egg_info\n",
      "  writing src\\gluonnlp.egg-info\\PKG-INFO\n",
      "  writing dependency_links to src\\gluonnlp.egg-info\\dependency_links.txt\n",
      "  writing requirements to src\\gluonnlp.egg-info\\requires.txt\n",
      "  writing top-level names to src\\gluonnlp.egg-info\\top_level.txt\n",
      "  reading manifest file 'src\\gluonnlp.egg-info\\SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  warning: no files found matching '*.py' under directory 'gluonnlp'\n",
      "  warning: no previously-included files matching '*' found under directory 'tests'\n",
      "  warning: no previously-included files matching '*' found under directory 'scripts'\n",
      "  adding license file 'LICENSE'\n",
      "  writing manifest file 'src\\gluonnlp.egg-info\\SOURCES.txt'\n",
      "  copying src\\gluonnlp\\data\\fast_bert_tokenizer.c -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\fast_bert_tokenizer.pyx -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  running build_ext\n",
      "  skipping 'src/gluonnlp/data\\fast_bert_tokenizer.c' Cython extension (up-to-date)\n",
      "  building 'gluonnlp.data.fast_bert_tokenizer' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for gluonnlp\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'C:\\Users\\User\\na\\envs\\kobert\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\User\\\\AppData\\\\Local\\\\Temp\\\\pip-install-1o02l1hm\\\\gluonnlp_1661501b992548a39b10db7fae2c0755\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\User\\\\AppData\\\\Local\\\\Temp\\\\pip-install-1o02l1hm\\\\gluonnlp_1661501b992548a39b10db7fae2c0755\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\User\\AppData\\Local\\Temp\\pip-record-93gurvml\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\User\\na\\envs\\kobert\\Include\\gluonnlp'\n",
      "         cwd: C:\\Users\\User\\AppData\\Local\\Temp\\pip-install-1o02l1hm\\gluonnlp_1661501b992548a39b10db7fae2c0755\\\n",
      "    Complete output (124 lines):\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build\\lib.win-amd64-3.6\n",
      "    creating build\\lib.win-amd64-3.6\\gluonnlp\n",
      "    copying src\\gluonnlp\\base.py -> build\\lib.win-amd64-3.6\\gluonnlp\n",
      "    copying src\\gluonnlp\\_constants.py -> build\\lib.win-amd64-3.6\\gluonnlp\n",
      "    copying src\\gluonnlp\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\n",
      "    creating build\\lib.win-amd64-3.6\\gluonnlp\\calibration\n",
      "    copying src\\gluonnlp\\calibration\\collector.py -> build\\lib.win-amd64-3.6\\gluonnlp\\calibration\n",
      "    copying src\\gluonnlp\\calibration\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\calibration\n",
      "    creating build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\baidu_ernie_data.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\candidate_sampler.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\classification.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\conll.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\dataloader.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\dataset.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\datasetloader.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\glue.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\intent_slot.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\question_answering.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\registry.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\sampler.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\sentiment.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\stream.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\super_glue.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\transforms.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\translation.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\utils.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\word_embedding_evaluation.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    creating build\\lib.win-amd64-3.6\\gluonnlp\\embedding\n",
      "    copying src\\gluonnlp\\embedding\\evaluation.py -> build\\lib.win-amd64-3.6\\gluonnlp\\embedding\n",
      "    copying src\\gluonnlp\\embedding\\token_embedding.py -> build\\lib.win-amd64-3.6\\gluonnlp\\embedding\n",
      "    copying src\\gluonnlp\\embedding\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\embedding\n",
      "    creating build\\lib.win-amd64-3.6\\gluonnlp\\initializer\n",
      "    copying src\\gluonnlp\\initializer\\initializer.py -> build\\lib.win-amd64-3.6\\gluonnlp\\initializer\n",
      "    copying src\\gluonnlp\\initializer\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\initializer\n",
      "    creating build\\lib.win-amd64-3.6\\gluonnlp\\loss\n",
      "    copying src\\gluonnlp\\loss\\activation_regularizer.py -> build\\lib.win-amd64-3.6\\gluonnlp\\loss\n",
      "    copying src\\gluonnlp\\loss\\label_smoothing.py -> build\\lib.win-amd64-3.6\\gluonnlp\\loss\n",
      "    copying src\\gluonnlp\\loss\\loss.py -> build\\lib.win-amd64-3.6\\gluonnlp\\loss\n",
      "    copying src\\gluonnlp\\loss\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\loss\n",
      "    creating build\\lib.win-amd64-3.6\\gluonnlp\\metric\n",
      "    copying src\\gluonnlp\\metric\\length_normalized_loss.py -> build\\lib.win-amd64-3.6\\gluonnlp\\metric\n",
      "    copying src\\gluonnlp\\metric\\masked_accuracy.py -> build\\lib.win-amd64-3.6\\gluonnlp\\metric\n",
      "    copying src\\gluonnlp\\metric\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\metric\n",
      "    creating build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\attention_cell.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\bert.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\bilm_encoder.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\block.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\convolutional_encoder.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\elmo.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\highway.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\info.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\language_model.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\lstmpcellwithclip.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\parameter.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\sampled_block.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\seq2seq_encoder_decoder.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\sequence_sampler.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\transformer.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\translation.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\utils.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "    creating build\\lib.win-amd64-3.6\\gluonnlp\\optimizer\n",
      "    copying src\\gluonnlp\\optimizer\\bert_adam.py -> build\\lib.win-amd64-3.6\\gluonnlp\\optimizer\n",
      "    copying src\\gluonnlp\\optimizer\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\optimizer\n",
      "    creating build\\lib.win-amd64-3.6\\gluonnlp\\utils\n",
      "    copying src\\gluonnlp\\utils\\files.py -> build\\lib.win-amd64-3.6\\gluonnlp\\utils\n",
      "    copying src\\gluonnlp\\utils\\parallel.py -> build\\lib.win-amd64-3.6\\gluonnlp\\utils\n",
      "    copying src\\gluonnlp\\utils\\parameter.py -> build\\lib.win-amd64-3.6\\gluonnlp\\utils\n",
      "    copying src\\gluonnlp\\utils\\seed.py -> build\\lib.win-amd64-3.6\\gluonnlp\\utils\n",
      "    copying src\\gluonnlp\\utils\\version.py -> build\\lib.win-amd64-3.6\\gluonnlp\\utils\n",
      "    copying src\\gluonnlp\\utils\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\utils\n",
      "    creating build\\lib.win-amd64-3.6\\gluonnlp\\vocab\n",
      "    copying src\\gluonnlp\\vocab\\bert.py -> build\\lib.win-amd64-3.6\\gluonnlp\\vocab\n",
      "    copying src\\gluonnlp\\vocab\\elmo.py -> build\\lib.win-amd64-3.6\\gluonnlp\\vocab\n",
      "    copying src\\gluonnlp\\vocab\\subwords.py -> build\\lib.win-amd64-3.6\\gluonnlp\\vocab\n",
      "    copying src\\gluonnlp\\vocab\\vocab.py -> build\\lib.win-amd64-3.6\\gluonnlp\\vocab\n",
      "    copying src\\gluonnlp\\vocab\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\vocab\n",
      "    creating build\\lib.win-amd64-3.6\\gluonnlp\\data\\batchify\n",
      "    copying src\\gluonnlp\\data\\batchify\\batchify.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\batchify\n",
      "    copying src\\gluonnlp\\data\\batchify\\embedding.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\batchify\n",
      "    copying src\\gluonnlp\\data\\batchify\\language_model.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\batchify\n",
      "    copying src\\gluonnlp\\data\\batchify\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\batchify\n",
      "    creating build\\lib.win-amd64-3.6\\gluonnlp\\data\\bert\n",
      "    copying src\\gluonnlp\\data\\bert\\glue.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\bert\n",
      "    copying src\\gluonnlp\\data\\bert\\squad.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\bert\n",
      "    copying src\\gluonnlp\\data\\bert\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\bert\n",
      "    creating build\\lib.win-amd64-3.6\\gluonnlp\\data\\corpora\n",
      "    copying src\\gluonnlp\\data\\corpora\\google_billion_word.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\corpora\n",
      "    copying src\\gluonnlp\\data\\corpora\\large_text_compression_benchmark.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\corpora\n",
      "    copying src\\gluonnlp\\data\\corpora\\wikitext.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\corpora\n",
      "    copying src\\gluonnlp\\data\\corpora\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\corpora\n",
      "    creating build\\lib.win-amd64-3.6\\gluonnlp\\data\\xlnet\n",
      "    copying src\\gluonnlp\\data\\xlnet\\squad.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\xlnet\n",
      "    copying src\\gluonnlp\\data\\xlnet\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\xlnet\n",
      "    creating build\\lib.win-amd64-3.6\\gluonnlp\\model\\train\n",
      "    copying src\\gluonnlp\\model\\train\\cache.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\\train\n",
      "    copying src\\gluonnlp\\model\\train\\embedding.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\\train\n",
      "    copying src\\gluonnlp\\model\\train\\language_model.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\\train\n",
      "    copying src\\gluonnlp\\model\\train\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\\train\n",
      "    running egg_info\n",
      "    writing src\\gluonnlp.egg-info\\PKG-INFO\n",
      "    writing dependency_links to src\\gluonnlp.egg-info\\dependency_links.txt\n",
      "    writing requirements to src\\gluonnlp.egg-info\\requires.txt\n",
      "    writing top-level names to src\\gluonnlp.egg-info\\top_level.txt\n",
      "    reading manifest file 'src\\gluonnlp.egg-info\\SOURCES.txt'\n",
      "    reading manifest template 'MANIFEST.in'\n",
      "    warning: no files found matching '*.py' under directory 'gluonnlp'\n",
      "    warning: no previously-included files matching '*' found under directory 'tests'\n",
      "    warning: no previously-included files matching '*' found under directory 'scripts'\n",
      "    adding license file 'LICENSE'\n",
      "    writing manifest file 'src\\gluonnlp.egg-info\\SOURCES.txt'\n",
      "    copying src\\gluonnlp\\data\\fast_bert_tokenizer.c -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\fast_bert_tokenizer.pyx -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    running build_ext\n",
      "    skipping 'src/gluonnlp/data\\fast_bert_tokenizer.c' Cython extension (up-to-date)\n",
      "    building 'gluonnlp.data.fast_bert_tokenizer' extension\n",
      "    error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'C:\\Users\\User\\na\\envs\\kobert\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\User\\\\AppData\\\\Local\\\\Temp\\\\pip-install-1o02l1hm\\\\gluonnlp_1661501b992548a39b10db7fae2c0755\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\User\\\\AppData\\\\Local\\\\Temp\\\\pip-install-1o02l1hm\\\\gluonnlp_1661501b992548a39b10db7fae2c0755\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\User\\AppData\\Local\\Temp\\pip-record-93gurvml\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\User\\na\\envs\\kobert\\Include\\gluonnlp' Check the logs for full command output.\n"
     ]
    }
   ],
   "source": [
    "!pip install gluonnlp pandas tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53393,
     "status": "ok",
     "timestamp": 1658293897729,
     "user": {
      "displayName": "문지현",
      "userId": "07420081825015725286"
     },
     "user_tz": -540
    },
    "id": "xuAWFBQlvu7w",
    "outputId": "ecbb66b6-caf5-4b82-93da-5d7a25d7a351"
   },
   "outputs": [],
   "source": [
    "!pip install mxnet==1.6.0 gluonnlp==0.9.1 sentencepiece==0.1.91 pandas==1.0.5 transformers==2.11.0 pytorch_lightning==0.8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53393,
     "status": "ok",
     "timestamp": 1658293897729,
     "user": {
      "displayName": "문지현",
      "userId": "07420081825015725286"
     },
     "user_tz": -540
    },
    "id": "xuAWFBQlvu7w",
    "outputId": "ecbb66b6-caf5-4b82-93da-5d7a25d7a351"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (0.1.91)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53393,
     "status": "ok",
     "timestamp": 1658293897729,
     "user": {
      "displayName": "문지현",
      "userId": "07420081825015725286"
     },
     "user_tz": -540
    },
    "id": "xuAWFBQlvu7w",
    "outputId": "ecbb66b6-caf5-4b82-93da-5d7a25d7a351"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==3.0.2 in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (3.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from transformers==3.0.2) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from transformers==3.0.2) (2.18.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from transformers==3.0.2) (3.4.1)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from transformers==3.0.2) (0.0.53)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from transformers==3.0.2) (4.64.0)\n",
      "Requirement already satisfied: dataclasses in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from transformers==3.0.2) (0.8)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from transformers==3.0.2) (0.1.91)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from transformers==3.0.2) (21.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from transformers==3.0.2) (1.16.6)\n",
      "Requirement already satisfied: tokenizers==0.8.1.rc1 in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from transformers==3.0.2) (0.8.1rc1)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from tqdm>=4.27->transformers==3.0.2) (5.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from tqdm>=4.27->transformers==3.0.2) (0.4.5)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from importlib-resources->tqdm>=4.27->transformers==3.0.2) (3.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from packaging->transformers==3.0.2) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from requests->transformers==3.0.2) (1.22)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from requests->transformers==3.0.2) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from requests->transformers==3.0.2) (2021.5.30)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from requests->transformers==3.0.2) (2.6)\n",
      "Requirement already satisfied: click in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from sacremoses->transformers==3.0.2) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from sacremoses->transformers==3.0.2) (1.1.0)\n",
      "Requirement already satisfied: six in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from sacremoses->transformers==3.0.2) (1.16.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from click->sacremoses->transformers==3.0.2) (4.8.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from importlib-metadata->click->sacremoses->transformers==3.0.2) (4.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==3.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53393,
     "status": "ok",
     "timestamp": 1658293897729,
     "user": {
      "displayName": "문지현",
      "userId": "07420081825015725286"
     },
     "user_tz": -540
    },
    "id": "xuAWFBQlvu7w",
    "outputId": "ecbb66b6-caf5-4b82-93da-5d7a25d7a351"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4165374143.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [16]\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install torch===1.7.0 torchvision===0.8.1 -f https://download.pytorch.org/whl/torch_stable.html\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# !pip install torch\n",
    "#pip install torch===1.7.0 torchvision===0.8.1 -f https://download.pytorch.org/whl/torch_stable.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53393,
     "status": "ok",
     "timestamp": 1658293897729,
     "user": {
      "displayName": "문지현",
      "userId": "07420081825015725286"
     },
     "user_tz": -540
    },
    "id": "xuAWFBQlvu7w",
    "outputId": "ecbb66b6-caf5-4b82-93da-5d7a25d7a351"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n",
      "  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to c:\\users\\user\\appdata\\local\\temp\\pip-req-build-yea5dago\n",
      "  Resolved https://****@github.com/SKTBrain/KoBERT.git to commit e1f2f37055e7460d8427f6912579c0162cb69831\n",
      "Collecting boto3\n",
      "  Using cached boto3-1.23.10-py3-none-any.whl (132 kB)\n",
      "Collecting gluonnlp>=0.6.0\n",
      "  Using cached gluonnlp-0.10.0.tar.gz (344 kB)\n",
      "Requirement already satisfied: mxnet>=1.4.0 in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from kobert==0.2.3) (1.6.0)\n",
      "Collecting onnxruntime==1.8.0\n",
      "  Using cached onnxruntime-1.8.0-cp36-cp36m-win_amd64.whl (4.7 MB)\n",
      "Requirement already satisfied: sentencepiece>=0.1.6 in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from kobert==0.2.3) (0.1.91)\n",
      "Requirement already satisfied: torch>=1.7.0 in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from kobert==0.2.3) (1.10.2)\n",
      "Collecting transformers>=4.8.1\n",
      "  Using cached transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
      "Collecting flatbuffers\n",
      "  Using cached flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: protobuf in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from onnxruntime==1.8.0->kobert==0.2.3) (3.19.4)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from onnxruntime==1.8.0->kobert==0.2.3) (1.16.6)\n",
      "Requirement already satisfied: cython in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from gluonnlp>=0.6.0->kobert==0.2.3) (0.29.30)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from gluonnlp>=0.6.0->kobert==0.2.3) (21.3)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from mxnet>=1.4.0->kobert==0.2.3) (0.8.4)\n",
      "Requirement already satisfied: requests<2.19.0,>=2.18.4 in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from mxnet>=1.4.0->kobert==0.2.3) (2.18.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from requests<2.19.0,>=2.18.4->mxnet>=1.4.0->kobert==0.2.3) (2021.5.30)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from requests<2.19.0,>=2.18.4->mxnet>=1.4.0->kobert==0.2.3) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from requests<2.19.0,>=2.18.4->mxnet>=1.4.0->kobert==0.2.3) (1.22)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from requests<2.19.0,>=2.18.4->mxnet>=1.4.0->kobert==0.2.3) (2.6)\n",
      "Requirement already satisfied: dataclasses in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from torch>=1.7.0->kobert==0.2.3) (0.8)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from torch>=1.7.0->kobert==0.2.3) (4.1.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from transformers>=4.8.1->kobert==0.2.3) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from transformers>=4.8.1->kobert==0.2.3) (2022.7.9)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Using cached huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from transformers>=4.8.1->kobert==0.2.3) (0.0.53)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from transformers>=4.8.1->kobert==0.2.3) (4.8.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from transformers>=4.8.1->kobert==0.2.3) (3.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\na\\envs\\kobert\\lib\\site-packages (from transformers>=4.8.1->kobert==0.2.3) (4.64.0)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Using cached tokenizers-0.12.1.tar.gz (220 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Collecting transformers>=4.8.1\n",
      "  Using cached transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
      "  Using cached transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
      "  Using cached transformers-4.16.1-py3-none-any.whl (3.5 MB)\n",
      "  Using cached transformers-4.16.0-py3-none-any.whl (3.5 MB)\n",
      "  Using cached transformers-4.15.0-py3-none-any.whl (3.4 MB)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Using cached tokenizers-0.10.3-cp36-cp36m-win_amd64.whl (2.0 MB)\n",
      "Collecting transformers>=4.8.1\n",
      "  Using cached transformers-4.14.1-py3-none-any.whl (3.4 MB)\n",
      "  Using cached transformers-4.13.0-py3-none-any.whl (3.3 MB)\n",
      "  Using cached transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
      "  Using cached transformers-4.12.4-py3-none-any.whl (3.1 MB)\n",
      "  Using cached transformers-4.12.3-py3-none-any.whl (3.1 MB)\n",
      "  Using cached transformers-4.12.2-py3-none-any.whl (3.1 MB)\n",
      "  Using cached transformers-4.12.1-py3-none-any.whl (3.1 MB)\n",
      "  Using cached transformers-4.12.0-py3-none-any.whl (3.1 MB)\n",
      "  Using cached transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
      "  Using cached transformers-4.11.2-py3-none-any.whl (2.9 MB)\n",
      "  Using cached transformers-4.11.1-py3-none-any.whl (2.9 MB)\n",
      "  Using cached transformers-4.11.0-py3-none-any.whl (2.9 MB)\n",
      "  Using cached transformers-4.10.3-py3-none-any.whl (2.8 MB)\n",
      "  Using cached transformers-4.10.2-py3-none-any.whl (2.8 MB)\n",
      "  Using cached transformers-4.10.1-py3-none-any.whl (2.8 MB)\n",
      "  Using cached transformers-4.10.0-py3-none-any.whl (2.8 MB)\n",
      "  Using cached transformers-4.9.2-py3-none-any.whl (2.6 MB)\n",
      "Collecting huggingface-hub==0.0.12\n",
      "  Using cached huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
      "Collecting transformers>=4.8.1\n",
      "  Using cached transformers-4.9.1-py3-none-any.whl (2.6 MB)\n",
      "  Using cached transformers-4.9.0-py3-none-any.whl (2.6 MB)\n",
      "  Using cached transformers-4.8.2-py3-none-any.whl (2.5 MB)\n",
      "  Using cached transformers-4.8.1-py3-none-any.whl (2.5 MB)\n",
      "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torch>=1.7.0\n",
      "  Using cached torch-1.10.2-cp36-cp36m-win_amd64.whl (226.6 MB)\n",
      "  Using cached torch-1.10.1-cp36-cp36m-win_amd64.whl (226.6 MB)\n",
      "  Using cached torch-1.10.0-cp36-cp36m-win_amd64.whl (226.6 MB)\n",
      "  Using cached torch-1.9.1-cp36-cp36m-win_amd64.whl (222.0 MB)\n",
      "  Using cached torch-1.9.0-cp36-cp36m-win_amd64.whl (222.0 MB)\n",
      "  Using cached torch-1.8.1-cp36-cp36m-win_amd64.whl (190.5 MB)\n",
      "  Using cached torch-1.8.0-cp36-cp36m-win_amd64.whl (190.5 MB)\n",
      "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached torch-1.7.1-cp36-cp36m-win_amd64.whl (184.1 MB)\n",
      "  Using cached torch-1.7.0-cp36-cp36m-win_amd64.whl (184.0 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' 'C:\\Users\\User\\AppData\\Local\\Temp\\pip-req-build-yea5dago'\n",
      "ERROR: torch has an invalid wheel, .dist-info directory not found\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master\n",
    "# !curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20273,
     "status": "ok",
     "timestamp": 1658293917984,
     "user": {
      "displayName": "문지현",
      "userId": "07420081825015725286"
     },
     "user_tz": -540
    },
    "id": "QmlBlmATJyd7",
    "outputId": "99143627-7b40-41f9-b873-5efcdccd03f8"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gluonnlp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgluonnlp\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnlp\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm, tqdm_notebook\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gluonnlp'"
     ]
    }
   ],
   "source": [
    "# torch\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "#kobert\n",
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "\n",
    "#GPU 사용\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "#BERT 모델, Vocabulary 불러오기 필수\n",
    "bertmodel, vocab = get_pytorch_kobert_model()\n",
    "\n",
    "\n",
    "# KoBERT에 입력될 데이터셋 정리\n",
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))  \n",
    "\n",
    "# 모델 정의\n",
    "class BERTClassifier(nn.Module): ## 클래스를 상속\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=2,   ##클래스 수 조정##\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)\n",
    "\n",
    "# Setting parameters\n",
    "max_len = 64\n",
    "batch_size = 32\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 5\n",
    "max_grad_norm = 1\n",
    "log_interval = 100\n",
    "learning_rate =  5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14395,
     "status": "ok",
     "timestamp": 1658293932354,
     "user": {
      "displayName": "문지현",
      "userId": "07420081825015725286"
     },
     "user_tz": -540
    },
    "id": "vGR4Ka7nAvU8",
    "outputId": "ec8fcde6-2db8-4932-af00-c54273b9a574"
   },
   "outputs": [],
   "source": [
    "## 학습 모델 로드\n",
    "PATH = '/content/drive/MyDrive/'\n",
    "model = torch.load(PATH + 'KoBERT_comment.pt')  # 전체 모델을 통째로 불러옴, 클래스 선언 필수\n",
    "model.load_state_dict(torch.load(PATH + 'model_state_dict.pt'))  # state_dict를 불러 온 후, 모델에 저장\n",
    "\n",
    "#토큰화\n",
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
    "\n",
    "def new_softmax(a) : \n",
    "    c = np.max(a) # 최댓값\n",
    "    exp_a = np.exp(a-c) # 각각의 원소에 최댓값을 뺀 값에 exp를 취한다. (이를 통해 overflow 방지)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = (exp_a / sum_exp_a) * 100\n",
    "    return np.round(y, 3)\n",
    "\n",
    "\n",
    "# 예측 모델 설정\n",
    "def predict(predict_sentence):\n",
    "\n",
    "    data = [predict_sentence, '0']\n",
    "    dataset_another = [data]\n",
    "\n",
    "    another_test = BERTDataset(dataset_another, 0, 1, tok, max_len, True, False)\n",
    "    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=5)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "\n",
    "\n",
    "        test_eval=[]\n",
    "        for i in out:\n",
    "            logits=i\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "\n",
    "            if np.argmax(logits) == 0:\n",
    "                test_eval.append(\"부정\")\n",
    "            elif np.argmax(logits) == 1:\n",
    "                test_eval.append(\"긍정\")\n",
    "        return test_eval\n",
    "\n",
    "#학습한 모델을 django에 로드할 때 필요한 클래스인 BERTDataset와 BERTClassifier은 manage.py에 세팅한 뒤에 모델을 Apps.py에서 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 568,
     "status": "ok",
     "timestamp": 1658294462164,
     "user": {
      "displayName": "문지현",
      "userId": "07420081825015725286"
     },
     "user_tz": -540
    },
    "id": "uxTUIWO3AEH0",
    "outputId": "53e83b9b-968c-4aec-e85a-3d73f0b930b7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "youtube_pd = pd.read_excel('/content/drive/MyDrive/MinHee_comment_2022-07-20_12_12_46.xlsx')\n",
    "youtube_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1658294555177,
     "user": {
      "displayName": "문지현",
      "userId": "07420081825015725286"
     },
     "user_tz": -540
    },
    "id": "5HCuPhEKrbAO"
   },
   "outputs": [],
   "source": [
    "def sentiment_comment(df):\n",
    "    import pandas as pd\n",
    "    df['comment'] = df['comment'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "    df = df.dropna()\n",
    "    df = df.reset_index(drop = True)\n",
    "    comment_df = pd.DataFrame(columns = ['video_name', 'com_id', 'comment', 'sentiment'])\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        comment_df.loc[i, 'video_name'] = df.loc[i, 'video_name']\n",
    "        comment_df.loc[i, 'com_id'] = df.loc[i, 'com_id']\n",
    "        comment_df.loc[i, 'comment'] = df.loc[i, 'comment']\n",
    "        comment_df.loc[i, 'sentiment'] = predict(comment_df.loc[i, 'comment'])\n",
    "  \n",
    "    return comment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 747
    },
    "executionInfo": {
     "elapsed": 38573,
     "status": "ok",
     "timestamp": 1658294594657,
     "user": {
      "displayName": "문지현",
      "userId": "07420081825015725286"
     },
     "user_tz": -540
    },
    "id": "ry_LB0LosSAw",
    "outputId": "fa9cb8bf-b4cf-4af5-b11d-ca76877e4635"
   },
   "outputs": [],
   "source": [
    "sentiment_comment(youtube_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QrRKwJh1CE6-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "koBert_comment_model.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "nltk",
   "language": "python",
   "name": "nltk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
